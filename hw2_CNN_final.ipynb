{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea5c03bf",
   "metadata": {},
   "source": [
    "---\n",
    "# Homework 2: Convolutional Neural Networks (CNNs) (100 points)\n",
    "\n",
    "\n",
    "In this homework, we're going to build a specific convolutional neural network (CNN) architecture called LeNet and then train it on an image classification dataset (the same dataset as in homework 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e88cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "torch.set_num_threads(4)\n",
    "torch.set_num_interop_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42d4f5ec",
   "metadata": {},
   "source": [
    "# Loading Data (0 points)\n",
    "\n",
    "This is an example of building a torch data loader for a dataset. Here we have used it to load the Fashion MNIST image dataset. No code needed here.\n",
    "\n",
    "The raw data is retrieved from: [Kaggle - Fashion MNIST Dataset](https://www.kaggle.com/datasets/zalando-research/fashionmnist?resource=download)\n",
    "\n",
    "We have already built a set of training, validation and test data for this homework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c1733f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv=pd.read_csv('../../assets/fashion_mnist/train.csv')\n",
    "test_csv=pd.read_csv('../../assets/fashion_mnist/test.csv')\n",
    "valid_csv=pd.read_csv('../../assets/fashion_mnist/val.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "395f1138",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionDataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, data, transform = None):\n",
    "        \"\"\"Method to initilaize variables.\"\"\" \n",
    "        self.fashion_MNIST = list(data.values)\n",
    "        self.transform = transform\n",
    "        \n",
    "        label = []\n",
    "        image = []\n",
    "        \n",
    "        for i in self.fashion_MNIST:\n",
    "             # first column is of labels.\n",
    "            label.append(i[0])\n",
    "            image.append(i[1:])\n",
    "        self.labels = np.asarray(label)\n",
    "        # Dimension of Images = 28 * 28 * 1. where height = width = 28 and color_channels = 1.\n",
    "        self.images = np.asarray(image).reshape(-1, 28, 28, 1).astype('float32')\n",
    "        self.images = self.images/256\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        label = self.labels[index]\n",
    "        image = self.images[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8af00e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "\n",
    "train_set = FashionDataset(train_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "val_set = FashionDataset(valid_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "test_set = FashionDataset(test_csv, transform=transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da51a52e",
   "metadata": {},
   "source": [
    "# Question 1: Build LeNet (50 pts)\n",
    "\n",
    "In this part, you will build a LeNet Model.\n",
    "\n",
    "The input to the model initialization should include the sizes of two hidden layers and the sizes of the output channels of two convolutional layers. You can refer to the original LeNet paper ([Gradient-based learning applied to document recognition](https://ieeexplore.ieee.org/document/726791)) for more details on the model. \n",
    "\n",
    "To improve the performance, you may consider adding batch normalization ([Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)) after each convolutional layer.\n",
    "\n",
    "You may put all of your modules inside the nn.Sequential function, so it will be easy to \"forward\" the input. \n",
    "\n",
    "We have prepared the model initialization for you. We have used a Xavier uniform initialization for linear layers and convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d94f512",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "45468e4c89c0e53f3b0754c4c305cae8",
     "grade": false,
     "grade_id": "cell-088f262b44f374c4",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class leNet(nn.Module):\n",
    "    def __init__(self,hidden_1=80,hidden_2=84,output_channel_1=4,output_channel_2=12):\n",
    "        super(leNet, self).__init__()\n",
    "        self.net=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=output_channel_1, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(output_channel_1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Conv2d(in_channels=output_channel_1, out_channels=output_channel_2, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(output_channel_2),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2, stride=2, padding=0),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=output_channel_2*4*4, out_features=hidden_1),\n",
    "            nn.BatchNorm1d(hidden_1),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=hidden_1, out_features=hidden_2),\n",
    "            nn.BatchNorm1d(hidden_2),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=hidden_2, out_features=10)\n",
    "        )\n",
    "        \n",
    "        # Xavier initialization for each module in the network.\n",
    "        for m in self.net:\n",
    "            if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f2f42d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters to consider, we just tune output_channel in this homework\n",
    "lrs=[0.9,1.5]\n",
    "hidden_1=80\n",
    "hidden_2=84\n",
    "output_channel_1s=[4,6]\n",
    "output_channel_2s=[12,16]\n",
    "# loss function\n",
    "loss_function = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29ea21f0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "008b9eec5c968e7bf30ba689f12294c5",
     "grade": false,
     "grade_id": "cell-5b12481db6346b00",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# function for evaluating a model's performance\n",
    "def eval_model(model,data_loader):\n",
    "    model.eval()\n",
    "    y_true_list=[]\n",
    "    y_pred_list=[]\n",
    "    model.eval()\n",
    "    for x,y in data_loader:\n",
    "        outputs=model(x)\n",
    "        _, y_pred = torch.max(outputs, 1)\n",
    "        y_pred_list.extend(y_pred.clone().detach().tolist())\n",
    "        y_true_list.extend(y.clone().detach().tolist())\n",
    "    acc=classification_report(y_true_list, y_pred_list,output_dict=True)['accuracy']\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea02cccc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "17a947b175a10b5b99735b20606ab69f",
     "grade": true,
     "grade_id": "cell-d59583a165f1e1ec",
     "locked": true,
     "points": 50,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5182db",
   "metadata": {},
   "source": [
    "# Question 2: Train the LeNet CNN model (50 pts)\n",
    "\n",
    "In this question, you will write a few lines to train the LeNet you just build.\n",
    "\n",
    "This is similar to Homework 1. \n",
    "\n",
    "Here's the list of things that you need to implement. All of them can (should) be done using one line of code.\n",
    "\n",
    "    Initialize the model with a set of hyperparameters\n",
    "    Initialize the optimizer with the model's trainable parameters\n",
    "    Set the model into the training mode\n",
    "    For every batch of data: \n",
    "        zero the gradient in the optimizer\n",
    "        feed the input into the model\n",
    "        compute the loss\n",
    "        back propagate the loss\n",
    "        update the optimizer\n",
    "        \n",
    "Your model should obtain a test set accuracy of at least 0.85 in order to secure full points. A training procedure that is correct but yields an accuracy lower than 0.85 will receive 25 points. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a03020",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8823475f73e193be63a05db9c7e33526",
     "grade": false,
     "grade_id": "cell-1778d34fd8d421bb",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 3407\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9e47d7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c64f1e4a084ebdaf93c650e5ccb1d7a",
     "grade": false,
     "grade_id": "cell-3f1e37b94323346b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "start_time=time.time()\n",
    "current_best=0\n",
    "best_model=0\n",
    "import torch.optim as optim\n",
    "for output_channel_1 in output_channel_1s:\n",
    "    for output_channel_2 in output_channel_2s:\n",
    "        for lr in lrs:\n",
    "            model = leNet(hidden_1=hidden_1,hidden_2=hidden_2,output_channel_1=output_channel_1,output_channel_2=output_channel_2)\n",
    "#             optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "            optimizer = optim.Adagrad(model.parameters(), lr=lr)\n",
    "            for i in range(20):\n",
    "#                 print(f\"epoch started for output_chanel1: {output_channel_1},output_channel_2: {output_channel_2},lr: {lr}\")\n",
    "                model.train()\n",
    "                for x, y in train_loader:\n",
    "                    optimizer.zero_grad()\n",
    "                    output = model(x)\n",
    "                    loss = loss_function(output, y)\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                if (i % 5) ==0:\n",
    "#                     model.eval()\n",
    "                    accuracy = eval_model(model, val_loader)\n",
    "                    if accuracy > current_best:\n",
    "                        current_best = accuracy\n",
    "                        best_model=copy.deepcopy(model)\n",
    "#                         best_model = model.state_dict()\n",
    "#                     model.train()\n",
    "#                     print(f\"Epoch {i+1}: accuracy = {accuracy}\")                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a71b448",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8871c2ca2ba37624eb92ebc9755bd550",
     "grade": true,
     "grade_id": "cell-cecbf8775ad12a3b",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e316ce",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6af0d63d42cd3b958bcdf28c5852a4fd",
     "grade": true,
     "grade_id": "cell-0c98fc8ebf4fb8b2",
     "locked": true,
     "points": 25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests in this cell"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_deep_learning_v1_hw2-CNN"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
