{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28cebfb5",
   "metadata": {},
   "source": [
    "---\n",
    "# Homework 3: Sequence to Sequence (Seq2Seq) Models (100 points)\n",
    "\n",
    "In this homework, we're going to build a sequence to sequence (seq2seq) model and train it on a French to English machine translation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b2990cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import copy\n",
    "torch.set_num_threads(4)\n",
    "torch.set_num_interop_threads(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79db0280",
   "metadata": {},
   "source": [
    "# Loading Data (0 points)\n",
    "\n",
    "This is an example of building a torch data loader for a dataset. No code needed here.\n",
    "\n",
    "The raw data is retrieved from: [Many Things - Tab-delimited Bilingual Sentence Pairs](http://www.manythings.org/anki/)\n",
    "\n",
    "We have already built a small subset of training, validation, and test data for this homework.\n",
    "\n",
    "We don't necessarily need dataloader for test/validation set in this homework since we won't use the validation dataset to select the model, but feel free to tune the model using the validation dataset.\n",
    "\n",
    "We will decode sentences in the test dataset one by one for simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff4bd7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv=pd.read_csv('assets/fr_en/train.csv')\n",
    "val_csv=pd.read_csv('assets/fr_en/val.csv')\n",
    "test_csv=pd.read_csv('assets/fr_en/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69d19256",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab,tgt_vocab={},{}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "618cda67",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokens=nltk.word_tokenize(' '.join(list(train_csv.en)))\n",
    "src_counters=Counter(src_tokens)\n",
    "src_vocab['token_freqs']=src_counters\n",
    "src_vocab['idx_to_token']=['<unk>','<pad>','<bos>','<eos>']+list(Counter(src_tokens).keys())\n",
    "token_to_idx={}\n",
    "for idx,token in enumerate(src_vocab['idx_to_token']):\n",
    "    token_to_idx[token]=idx\n",
    "src_vocab['token_to_idx']=token_to_idx\n",
    "src_vocab['bos']='<bos>'\n",
    "src_vocab['pad']='<pad>'\n",
    "src_vocab['unk']='<unk>'\n",
    "src_vocab['eos']='<eos>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20620d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_tokens=nltk.word_tokenize(' '.join(list(train_csv.fr)))\n",
    "tgt_counters=Counter(tgt_tokens)\n",
    "tgt_vocab['token_freqs']=tgt_counters\n",
    "tgt_vocab['idx_to_token']=['<unk>','<pad>','<bos>','<eos>']+list(Counter(tgt_tokens).keys())\n",
    "token_to_idx={}\n",
    "for idx,token in enumerate(tgt_vocab['idx_to_token']):\n",
    "    token_to_idx[token]=idx\n",
    "tgt_vocab['token_to_idx']=token_to_idx\n",
    "tgt_vocab['bos']='<bos>'\n",
    "tgt_vocab['pad']='<pad>'\n",
    "tgt_vocab['unk']='<unk>'\n",
    "tgt_vocab['eos']='<eos>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42dafee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMTDataset(Dataset):\n",
    "    \"\"\"User defined class to build a datset using Pytorch class Dataset.\"\"\"\n",
    "    \n",
    "    def __init__(self, dataframe, src_vocab, tgt_vocab,max_len=10):\n",
    "        \"\"\"Method to initilaize variables.\"\"\"\n",
    "        self.dataframe = dataframe\n",
    "        self.src_vocab = src_vocab\n",
    "        self.tgt_vocab = tgt_vocab\n",
    "        self.max_len = max_len\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        src_tensor = torch.full((self.max_len,),self.src_vocab['token_to_idx'][self.src_vocab['pad']])\n",
    "        src = self.dataframe.en[index].lower()\n",
    "        src_tokens = [src_vocab['bos']] + nltk.word_tokenize(src)\n",
    "        for i in range(min(self.max_len-1,len(src_tokens))):\n",
    "            src_tensor[i] = self.src_vocab['token_to_idx'][src_tokens[i]] if src_tokens[i] in self.src_vocab['token_to_idx'] \\\n",
    "                                                                        else self.src_vocab['token_to_idx'][self.src_vocab['unk']] \n",
    "        src_tensor[i+1]=self.src_vocab['token_to_idx'][self.src_vocab['eos']]\n",
    "        \n",
    "        tgt_tensor = torch.full((self.max_len,),self.tgt_vocab['token_to_idx'][self.tgt_vocab['pad']])\n",
    "        tgt = self.dataframe.fr[index].lower()\n",
    "        tgt_tokens = [tgt_vocab['bos']] + nltk.word_tokenize(tgt)\n",
    "        for i in range(min(self.max_len-1,len(tgt_tokens))):\n",
    "            tgt_tensor[i] = self.tgt_vocab['token_to_idx'][tgt_tokens[i]] if tgt_tokens[i] in self.tgt_vocab['token_to_idx'] \\\n",
    "                                                                        else self.tgt_vocab['token_to_idx'][self.tgt_vocab['unk']] \n",
    "        tgt_tensor[i+1]=self.tgt_vocab['token_to_idx'][self.tgt_vocab['eos']]\n",
    "\n",
    "        return src_tensor, tgt_tensor\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aba2b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "max_len=10\n",
    "\n",
    "train_set = NMTDataset(train_csv,src_vocab,tgt_vocab,max_len)\n",
    "# val_set = NMTDataset(val_csv,src_vocab,tgt_vocab,max_len)\n",
    "# test_set = NMTDataset(test_csv,src_vocab,tgt_vocab,max_len)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size)\n",
    "# val_loader = DataLoader(val_set, batch_size=batch_size)\n",
    "# test_loader = DataLoader(test_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94875e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 32, 32, 2, 0.1\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, device = 0.005, 300, d2l.try_gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f71024a",
   "metadata": {},
   "source": [
    "# Question 1: Build the encoder (30 pts)\n",
    "\n",
    "In this question, you will build a GRU encoder.\n",
    "\n",
    "An encoder should include an embedding layer and a RNN layer.\n",
    "\n",
    "The input to the model initialization should include the input dimension (source vocabulary size), the embedding dimension (which should also be the input dimension of the GRU layer), the hidden dimension of GRU, the number of layers of GRU, and dropout rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "446e7776",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7e8bde8232aa064e310946f54d7b6004",
     "grade": false,
     "grade_id": "cell-46d418152cf19863",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim, n_layers, dropout,**kwargs):\n",
    "        super(encoder,self).__init__(**kwargs)\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src):\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7542c800",
   "metadata": {},
   "source": [
    "# Question 2: Build the decoder (30 pts)\n",
    "\n",
    "In this part, you will build a GRU decoder.\n",
    "\n",
    "The decoder should include an embedding layer, a RNN layer, and a linear layer.\n",
    "\n",
    "The input to the model initialization should include the output dimension (target vocabulary size), the embedding dimension (which should also be the input dimension of the GRU layer), the hidden dimension of GRU, the number of layers of GRU, and dropout rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b487db14",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f1d1ce22f96c41263007510e60674320",
     "grade": false,
     "grade_id": "cell-d0d2339b9ff6d579",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim, n_layers, dropout,**kwargs):\n",
    "        super(decoder,self).__init__(**kwargs)\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, hid_dim, n_layers, dropout=dropout)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        output = self.fc_out(output.squeeze(0))\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05277ecb",
   "metadata": {},
   "source": [
    "# Question 3: Putting together the seq2seq model (30 pts)\n",
    "\n",
    "In this part, you will combine the encoder and decoder to build the seq2seq model.\n",
    "\n",
    "The seq2seq function below should include an encoder and a decoder. We also initialize a \"device\" in the code so that you can try the code on a GPU device.\n",
    "\n",
    "During the forward pass over the network in the \"forward\" function, please apply a \"teacher forcing strategy.\" It means that at each time step of decoding, the decoder will receive the ground truth token (instead of the predicted token) of that time step. Otherwise, one could also feed the output from the previous step. Teacher forcing helps stabilize model training by preventing error propagation from the previous training steps. But higher teacher forcing can also harm the model performance since the `teacher` could help too much. Hence, we define a hyperparameter that controls the teacher forcing ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0bf122c9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3222540beacda16dce07120e5090587f",
     "grade": false,
     "grade_id": "cell-08d851f0e0253a6f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class seq2seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device, **kwargs):\n",
    "        super(seq2seq, self).__init__(**kwargs)\n",
    "\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "        # make sure your dimension is correct\n",
    "        assert encoder.hid_dim == decoder.hid_dim, \\\n",
    "            \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert encoder.n_layers == decoder.n_layers, \\\n",
    "            \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "\n",
    "        # Transpose src and trg\n",
    "        src = src.transpose(0, 1)\n",
    "        trg = trg.transpose(0, 1)\n",
    "\n",
    "        batch_size = trg.size(0)\n",
    "        max_len = trg.size(1)\n",
    "\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        # Get hidden state from encoder\n",
    "        hidden = self.encoder(src)\n",
    "\n",
    "        # Use <bos> as the decoder input\n",
    "        input = trg[0, :]\n",
    "\n",
    "        for t in range(1, max_len):\n",
    "\n",
    "            # Get output and hidden state from decoder\n",
    "            output, hidden = self.decoder(input.unsqueeze(0), hidden)\n",
    "\n",
    "            # Save output to the outputs tensor\n",
    "            outputs[t] = output.squeeze(0)\n",
    "\n",
    "            # Decide whether to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            # Get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(dim=2)\n",
    "\n",
    "            # If teacher forcing, use actual next token as next input\n",
    "            # If not, use predicted token\n",
    "            input = trg[t] if teacher_force and t < (max_len-1) else top1.squeeze(1).detach()\n",
    "\n",
    "        # Transpose outputs and return\n",
    "        return outputs.transpose(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb90291b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4c397311e9b09f4148ba6b292435b8a2",
     "grade": true,
     "grade_id": "cell-e96b7088359f8c4a",
     "locked": true,
     "points": 90,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests in this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cad8dc",
   "metadata": {},
   "source": [
    "# Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f613bed9",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a9df6ede3825cbebb40cd09302b9c6e2",
     "grade": false,
     "grade_id": "cell-350d579de6a166e1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "random_seed = 3407\n",
    "torch.manual_seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01fdecc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc=encoder(len(src_vocab['idx_to_token']),embed_size,num_hiddens,num_layers,dropout)\n",
    "dec=decoder(len(tgt_vocab['idx_to_token']),embed_size,num_hiddens,num_layers,dropout)\n",
    "model=seq2seq(enc,dec,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b43228e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seq2seq(\n",
       "  (encoder): encoder(\n",
       "    (embedding): Embedding(1051, 32)\n",
       "    (gru): GRU(32, 32, num_layers=2, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): decoder(\n",
       "    (embedding): Embedding(2064, 32)\n",
       "    (rnn): GRU(32, 32, num_layers=2, dropout=0.1)\n",
       "    (fc_out): Linear(in_features=32, out_features=2064, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the parameters\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "    if type(m) == nn.GRU:\n",
    "        for param in m._flat_weights_names:\n",
    "            if \"weight\" in param:\n",
    "                nn.init.xavier_uniform_(m._parameters[param])\n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "553005cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=5e-3)\n",
    "# Ignore padding tokens when calculating the loss\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = tgt_vocab['token_to_idx'][tgt_vocab['pad']])\n",
    "# Clip the gradient to avoid gradient explosion\n",
    "clip=1\n",
    "teacher_forcing=0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee850364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoding outputs to real words function\n",
    "def decode_output(model,src_sent,src_vocab,tgt_vocab):\n",
    "    model.eval()\n",
    "    src_tensor = torch.full((10,),src_vocab['token_to_idx'][src_vocab['pad']])\n",
    "    src_tokens = [src_vocab['bos']] + nltk.word_tokenize(src_sent)\n",
    "    for i in range(min(9,len(src_tokens))):\n",
    "        src_tensor[i] = src_vocab['token_to_idx'][src_tokens[i]] if src_tokens[i] in src_vocab['token_to_idx'] \\\n",
    "                                                                    else src_vocab['token_to_idx'][src_vocab['unk']] \n",
    "    src_tensor[i+1]=src_vocab['token_to_idx'][src_vocab['eos']]\n",
    "    src_tensor=src_tensor.unsqueeze(1)\n",
    "    Y=torch.zeros(10,1).long()\n",
    "    Y[0][0]=tgt_vocab['token_to_idx'][tgt_vocab['bos']]\n",
    "    output=model(src_tensor,Y,0).squeeze().argmax(dim=1).tolist()\n",
    "    trg_sentence=''\n",
    "    for idx in output:\n",
    "        if idx==tgt_vocab['token_to_idx']['<eos>']:\n",
    "            break\n",
    "        trg_sentence+=tgt_vocab['idx_to_token'][idx]+' '\n",
    "    return trg_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "662cdf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating BLEU score\n",
    "def bleu(pred_seq, label_seq, k):\n",
    "    pred_tokens, label_tokens = nltk.word_tokenize(pred_seq), nltk.word_tokenize(label_seq)\n",
    "    len_pred, len_label = len(pred_tokens), len(label_tokens)\n",
    "    score = math.exp(min(0, 1 - len_label / len_pred))\n",
    "    for n in range(1, k + 1):\n",
    "        num_matches, label_subs = 0, collections.defaultdict(int)\n",
    "        for i in range(len_label - n + 1):\n",
    "            label_subs[' '.join(label_tokens[i: i + n])] += 1\n",
    "        for i in range(len_pred - n + 1):\n",
    "            if label_subs[' '.join(pred_tokens[i: i + n])] > 0:\n",
    "                num_matches += 1\n",
    "                label_subs[' '.join(pred_tokens[i: i + n])] -= 1\n",
    "        score *= math.pow(num_matches / (len_pred - n + 1), math.pow(0.5, n))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e05db89",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4af7e600f23b5e006b0797387a1b387c",
     "grade": false,
     "grade_id": "cell-d9fb2cc2dd332011",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the model's performance\n",
    "def eval_model(model,data_csv,src_vocab,tgt_vocab):\n",
    "    model.eval()\n",
    "    bleu_acc=0\n",
    "    for i in range(len(data_csv)):\n",
    "        src_sent = data_csv.iloc[i].en\n",
    "        label_seq = data_csv.iloc[i].fr\n",
    "        pred_seq = decode_output(model, src_sent, src_vocab, tgt_vocab)\n",
    "        bleu_acc += bleu(pred_seq, label_seq, 2)\n",
    "    return bleu_acc / len(data_csv) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de730f3",
   "metadata": {},
   "source": [
    "# Question 4: Clip the gradient (10 pts)\n",
    "\n",
    "Recall that the gradient of a RNN model can explode during model training.\n",
    "\n",
    "So, in this question, you will clip the gradient. \n",
    "\n",
    "Hint: It should be one line of code.\n",
    "\n",
    "Your final model BLEU score should be greater than 0.2 in order to get full credit for this homework. Code that is syntactically correct but that has a lower accuracy will lose half credit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d3acd0a",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d49be6c595a9ad0937f5b1f16d83fdd7",
     "grade": false,
     "grade_id": "cell-7bef6644daea5d59",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# epoch=500\n",
    "# loss_list=[]\n",
    "# current_best=0\n",
    "# best_model=0\n",
    "# for i in tqdm(range(epoch)):\n",
    "#     total_loss=0\n",
    "#     model.train()\n",
    "#     for batch in train_loader:\n",
    "#         X, Y= [x.to(device) for x in batch]\n",
    "#         # Transpose the data if you RNN above is not batch first\n",
    "#         X=X.transpose(0,1)\n",
    "#         Y=Y.transpose(0,1)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         output=model(X,Y,teacher_forcing)\n",
    "        \n",
    "#         # Remove the <bos> in the target sentence to calculate the loss\n",
    "#         tgt_Y=torch.cat((Y[1:,:],torch.full((1,Y.shape[1]),tgt_vocab['token_to_idx'][tgt_vocab['pad']])),dim=0)\n",
    "#         output = output.reshape(-1, output.shape[-1])\n",
    "#         tgt_Y= tgt_Y.reshape(-1)\n",
    "#         loss = criterion(output, tgt_Y)\n",
    "#         loss.backward()\n",
    "        \n",
    "#         # TODO: Clip the gradient\n",
    "#         # YOUR CODE HERE\n",
    "#         raise NotImplementedError()\n",
    "        \n",
    "#         optimizer.step()\n",
    "#         total_loss+=loss.item()\n",
    "        \n",
    "#     # Check the model performance every 50 epochs\n",
    "#     if (i+1)%50 == 0:\n",
    "#         val_bleu=eval_model(model,val_csv,src_vocab,tgt_vocab)\n",
    "#         if val_bleu > current_best:\n",
    "#             test_bleu=eval_model(model,test_csv,src_vocab,tgt_vocab)\n",
    "#             print(\"Current best model, Test BLEU:\", test_bleu)\n",
    "#             current_best=val_bleu\n",
    "#             best_model=copy.deepcopy(model)\n",
    "#     loss_list.append(total_loss/len(train_loader))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a7b226e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input must have 3 dimensions, got 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m Y\u001b[38;5;241m=\u001b[39mY\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 15\u001b[0m output\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY\u001b[49m\u001b[43m,\u001b[49m\u001b[43mteacher_forcing\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Remove the <bos> in the target sentence to calculate the loss\u001b[39;00m\n\u001b[1;32m     18\u001b[0m tgt_Y\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcat((Y[\u001b[38;5;241m1\u001b[39m:,:],torch\u001b[38;5;241m.\u001b[39mfull((\u001b[38;5;241m1\u001b[39m,Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]),tgt_vocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtoken_to_idx\u001b[39m\u001b[38;5;124m'\u001b[39m][tgt_vocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpad\u001b[39m\u001b[38;5;124m'\u001b[39m]])),dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36mseq2seq.forward\u001b[0;34m(self, src, trg, teacher_forcing_ratio)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m trg[\u001b[38;5;241m0\u001b[39m, :]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, max_len):\n\u001b[1;32m     35\u001b[0m \n\u001b[1;32m     36\u001b[0m     \u001b[38;5;66;03m# Get output and hidden state from decoder\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# Save output to the outputs tensor\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     outputs[t] \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mdecoder.forward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     18\u001b[0m embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(\u001b[38;5;28minput\u001b[39m))\n\u001b[0;32m---> 19\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc_out(output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, hidden\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:847\u001b[0m, in \u001b[0;36mGRU.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    843\u001b[0m     \u001b[38;5;66;03m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    844\u001b[0m     \u001b[38;5;66;03m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    845\u001b[0m     hx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 847\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_forward_args\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    849\u001b[0m     result \u001b[38;5;241m=\u001b[39m _VF\u001b[38;5;241m.\u001b[39mgru(\u001b[38;5;28minput\u001b[39m, hx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers,\n\u001b[1;32m    850\u001b[0m                      \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbidirectional, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:229\u001b[0m, in \u001b[0;36mRNNBase.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_forward_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, hidden: Tensor, batch_sizes: Optional[Tensor]):\n\u001b[0;32m--> 229\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    230\u001b[0m     expected_hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_expected_hidden_size(\u001b[38;5;28minput\u001b[39m, batch_sizes)\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcheck_hidden_size(hidden, expected_hidden_size)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/rnn.py:201\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    199\u001b[0m expected_input_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_sizes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m!=\u001b[39m expected_input_dim:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput must have \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m dimensions, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    203\u001b[0m             expected_input_dim, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mdim()))\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    205\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    206\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    207\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_size, \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input must have 3 dimensions, got 4"
     ]
    }
   ],
   "source": [
    "epoch=20\n",
    "loss_list=[]\n",
    "current_best=0\n",
    "best_model=0\n",
    "for i in tqdm(range(epoch)):\n",
    "    total_loss=0\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        X, Y= [x.to(device) for x in batch]\n",
    "        # Transpose the data if you RNN above is not batch first\n",
    "        X=X.transpose(0,1)\n",
    "        Y=Y.transpose(0,1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output=model(X,Y,teacher_forcing)\n",
    "        \n",
    "        # Remove the <bos> in the target sentence to calculate the loss\n",
    "        tgt_Y=torch.cat((Y[1:,:],torch.full((1,Y.shape[1]),tgt_vocab['token_to_idx'][tgt_vocab['pad']])),dim=0)\n",
    "        output = output.reshape(-1, output.shape[-1])\n",
    "        tgt_Y= tgt_Y.reshape(-1)\n",
    "        loss = criterion(output, tgt_Y)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        total_loss+=loss.item()\n",
    "        \n",
    "    # Check the model performance every 50 epochs\n",
    "    if (i+1)%10 == 0:\n",
    "        val_bleu=eval_model(model,val_csv,src_vocab,tgt_vocab)\n",
    "        if val_bleu > current_best:\n",
    "            test_bleu=eval_model(model,test_csv,src_vocab,tgt_vocab)\n",
    "            print(\"Current best model, Test BLEU:\", test_bleu)\n",
    "            current_best=val_bleu\n",
    "            best_model=copy.deepcopy(model)\n",
    "    loss_list.append(total_loss/len(train_loader))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266197e3",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "69856909c926546de2bfa0d48f2ca1d8",
     "grade": true,
     "grade_id": "cell-d7173453994bed71",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You should have at least 0.2 BELU\n",
    "# Hidden tests in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ad547d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bac48d7e98ad9f453fd52f035226735b",
     "grade": true,
     "grade_id": "cell-10d3f66986564fd9",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# You should have at least 0.2 BELU\n",
    "# Hidden tests in this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafeb205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the loss change over epochs\n",
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14def2d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8441a1802bf49950ef45e1b9e18f8dd8",
     "grade": true,
     "grade_id": "cell-3f3f77597d6bb198",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hidden tests in this cell\n",
    "# loss should decreasing every 50 epochs"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "schema_names": [
    "mads_deep_learning_v1_hw3-seq2seq"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
